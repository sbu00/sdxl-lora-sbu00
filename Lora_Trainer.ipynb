{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# â­ Lora Trainer by Hollowstrawberry\n",
        "\n",
        "This is based on the work of [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8clWTZEu-g"
      },
      "source": [
        "### â­• Disclaimer\n",
        "The purpose of this document is to research bleeding-edge technologies in the field of machine learning.  \n",
        "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPQlB4djNm3C"
      },
      "source": [
        "| |GitHub|ğŸ‡¬ğŸ‡§ English|ğŸ‡ªğŸ‡¸ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| ğŸ  **Homepage** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| ğŸ“Š **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| â­ **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| ğŸŒŸ **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| ğŸŒŸ **Legacy XL Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OglZzI_ujZq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5553fbc-78f1-4e18-f836-66d89a549a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ’¿ Checking dataset...\n",
            "ğŸ“MyDrive/Loras/mushroom/dataset\n",
            "ğŸ“ˆ Found 13 images with 20 repeats, equaling 260 steps.\n",
            "ğŸ“‰ Divide 260 steps by 1 batch size to get 260.0 steps per epoch.\n",
            "ğŸ”® There will be 10 epochs, for around 2600 total training steps.\n",
            "\n",
            "âœ… ä¾è³´åº«å·²å®‰è£ã€‚\n",
            "\n",
            "ğŸ”„ æ¨¡å‹å·²ä¸‹è¼‰ã€‚\n",
            "\n",
            "\n",
            "ğŸ“„ è¨­å®šæª”å·²å„²å­˜åˆ° /content/drive/MyDrive/Loras/mushroom/training_config.toml\n",
            "ğŸ“„ è³‡æ–™é›†è¨­å®šæª”å·²å„²å­˜åˆ° /content/drive/MyDrive/Loras/mushroom/dataset_config.toml\n",
            "\n",
            "â­ æ­£åœ¨å•Ÿå‹•è¨“ç·´å™¨...\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
            "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751267314.936680   15359 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751267314.942623   15359 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "Loading settings from /content/drive/MyDrive/Loras/mushroom/training_config.toml...\n",
            "/content/drive/MyDrive/Loras/mushroom/training_config\n",
            "prepare tokenizer\n",
            "update token length: 225\n",
            "Loading dataset config from /content/drive/MyDrive/Loras/mushroom/dataset_config.toml\n",
            "prepare images.\n",
            "found directory /content/drive/MyDrive/Loras/mushroom/dataset contains 13 image files\n",
            "No caption file found for 13 images. Training will continue without captions for these images. If class token exists, it will be used. / 13æšã®ç”»åƒã«ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã‚Œã‚‰ã®ç”»åƒã«ã¤ã„ã¦ã¯ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãªã—ã§å­¦ç¿’ã‚’ç¶šè¡Œã—ã¾ã™ã€‚class tokenãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ã„ã¾ã™ã€‚\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_back_starbag.png\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_birthday_cap_and_cake.png\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_crown_cap.png\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_graduation_cap.png\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_happy_jump_left.png\n",
            "/content/drive/MyDrive/Loras/mushroom/dataset/dgu_happy_jump_right.png... and 8 more\n",
            "260 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / æ­£å‰‡åŒ–ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: True\n",
            "  network_multiplier: 1.0\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 1024\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/Loras/mushroom/dataset\"\n",
            "    image_count: 13\n",
            "    num_repeats: 20\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 1\n",
            "    keep_tokens_separator: \n",
            "    caption_separator: ,\n",
            "    secondary_separator: None\n",
            "    enable_wildcard: False\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    caption_prefix: None\n",
            "    caption_suffix: None\n",
            "    color_aug: False\n",
            "    flip_aug: True\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    alpha_mask: False,\n",
            "    is_reg: False\n",
            "    class_tokens: mushroom\n",
            "    caption_extension: \n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 13/13 [00:00<00:00, 424.97it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / å„bucketã®ç”»åƒæšæ•°ï¼ˆç¹°ã‚Šè¿”ã—å›æ•°ã‚’å«ã‚€ï¼‰\n",
            "bucket 0: resolution (512, 512), count: 260\n",
            "mean ar error (without repeats): 0.0\n",
            "preparing accelerator\n",
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:439: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "accelerator device: cuda\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint: /content/animefull-final-pruned-fp16.safetensors\n",
            "UNet2DConditionModel: 64, 8, 768, False, False\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Enable xformers for U-Net\n",
            "import network module: networks.lora\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "checking cache validity...\n",
            "100% 13/13 [00:00<00:00, 155344.59it/s]\n",
            "caching latents...\n",
            " 62% 8/13 [00:04<00:02,  2.00it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 1017, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 634, in simple_launcher\n",
            "    process.wait()\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1277, in wait\n",
            "    self._wait(timeout=sigint_timeout)\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2047, in _wait\n",
            "    time.sleep(delay)\n",
            "KeyboardInterrupt\n",
            " 62% 8/13 [00:04<00:02,  1.85it/s]\n",
            "\n",
            "\u001b[38;5;15mTraceback (most recent call last):\u001b[39m\n",
            "\u001b[38;5;15m  File \u001b[39m\u001b[38;5;117;03m\"/content/kohya-trainer/train_network_wrapper.py\"\u001b[39;00m\u001b[38;5;15m, line \u001b[39m\u001b[38;5;141m10\u001b[39m\u001b[38;5;15m, in \u001b[39m\u001b[38;5;15m<module>\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;15mtrainer\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mtrain\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15margs\u001b[39m\u001b[38;5;15m)\u001b[39m\n",
            "\u001b[38;5;15m  File \u001b[39m\u001b[38;5;117;03m\"/content/kohya-trainer/train_network.py\"\u001b[39;00m\u001b[38;5;15m, line \u001b[39m\u001b[38;5;141m272\u001b[39m\u001b[38;5;15m, in \u001b[39m\u001b[38;5;15mtrain\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;15mtrain_dataset_group\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mcache_latents\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15mvae\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15margs\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mvae_batch_size\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15margs\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mcache_latents_to_disk\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15maccelerator\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mis_main_process\u001b[39m\u001b[38;5;15m)\u001b[39m\n",
            "\u001b[38;5;15m  File \u001b[39m\u001b[38;5;117;03m\"/content/kohya-trainer/library/train_util.py\"\u001b[39;00m\u001b[38;5;15m, line \u001b[39m\u001b[38;5;141m2202\u001b[39m\u001b[38;5;15m, in \u001b[39m\u001b[38;5;15mcache_latents\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;15mdataset\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mcache_latents\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15mvae\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mvae_batch_size\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mcache_to_disk\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mis_main_process\u001b[39m\u001b[38;5;15m)\u001b[39m\n",
            "\u001b[38;5;15m  File \u001b[39m\u001b[38;5;117;03m\"/content/kohya-trainer/library/train_util.py\"\u001b[39;00m\u001b[38;5;15m, line \u001b[39m\u001b[38;5;141m1097\u001b[39m\u001b[38;5;15m, in \u001b[39m\u001b[38;5;15mcache_latents\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;15mcache_batch_latents\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15mvae\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mcache_to_disk\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mbatch\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mcondition\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mflip_aug\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mcondition\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15malpha_mask\u001b[39m\u001b[38;5;15m,\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mcondition\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mrandom_crop\u001b[39m\u001b[38;5;15m)\u001b[39m\n",
            "\u001b[38;5;15m  File \u001b[39m\u001b[38;5;117;03m\"/content/kohya-trainer/library/train_util.py\"\u001b[39;00m\u001b[38;5;15m, line \u001b[39m\u001b[38;5;141m2586\u001b[39m\u001b[38;5;15m, in \u001b[39m\u001b[38;5;15mcache_batch_latents\u001b[39m\n",
            "\u001b[38;5;15m    \u001b[39m\u001b[38;5;15mlatents\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;212m=\u001b[39m\u001b[38;5;15m \u001b[39m\u001b[38;5;15mvae\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mencode\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15mimg_tensors\u001b[39m\u001b[38;5;15m)\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mlatent_dist\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15msample\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;15m)\u001b[39m\u001b[38;5;212m.\u001b[39m\u001b[38;5;15mto\u001b[39m\u001b[38;5;15m(\u001b[39m\u001b[38;5;228m\"\u001b[39m\u001b[38;5;228mcpu\u001b[39m\u001b[38;5;228m\"\u001b[39m\u001b[38;5;15m)\u001b[39m\n",
            "\u001b[38;5;15m              \u001b[39m\u001b[38;5;15m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[39m\n",
            "\u001b[38;5;15mKeyboardInterrupt\u001b[39m\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import toml\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# These carry information from past executions\n",
        "if \"model_url\" in globals():\n",
        "  old_model_url = model_url\n",
        "else:\n",
        "  old_model_url = None\n",
        "if \"dependencies_installed\" not in globals():\n",
        "  dependencies_installed = False\n",
        "if \"model_file\" not in globals():\n",
        "  model_file = None\n",
        "\n",
        "# These may be set by other cells, some are legacy\n",
        "if \"custom_dataset\" not in globals():\n",
        "  custom_dataset = None\n",
        "if \"override_dataset_config_file\" not in globals():\n",
        "  override_dataset_config_file = None\n",
        "if \"override_config_file\" not in globals():\n",
        "  override_config_file = None\n",
        "if \"optimizer\" not in globals():\n",
        "  optimizer = \"AdamW8bit\"\n",
        "if \"optimizer_args\" not in globals():\n",
        "  optimizer_args = None\n",
        "if \"continue_from_lora\" not in globals():\n",
        "  continue_from_lora = \"\"\n",
        "if \"weighted_captions\" not in globals():\n",
        "  weighted_captions = False\n",
        "if \"adjust_tags\" not in globals():\n",
        "  adjust_tags = False\n",
        "if \"keep_tokens_weight\" not in globals():\n",
        "  keep_tokens_weight = 1.0\n",
        "\n",
        "COLAB = True # low ram\n",
        "XFORMERS = True\n",
        "SOURCE = \"https://github.com/uYouUs/sd-scripts\"\n",
        "COMMIT = None\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#@title ## ğŸš© å¾é€™è£¡é–‹å§‹\n",
        "\n",
        "#@markdown ### â–¶ï¸ è¨­å®š\n",
        "#@markdown æ‚¨çš„å°ˆæ¡ˆåç¨±å°‡èˆ‡åŒ…å«æ‚¨åœ–ç‰‡çš„è³‡æ–™å¤¾åç¨±ç›¸åŒã€‚ä¸å…è¨±æœ‰ç©ºæ ¼ã€‚\n",
        "project_name = \"mushroom\" #@param {type:\"string\"}\n",
        "project_name = project_name.strip()\n",
        "#@markdown è³‡æ–™å¤¾çµæ§‹ä¸¦ä¸é‡è¦ï¼Œç´”ç²¹æ˜¯ç‚ºäº†æ–¹ä¾¿æ•´ç†ã€‚è«‹ç¢ºä¿å§‹çµ‚é¸æ“‡ç›¸åŒçš„çµæ§‹ã€‚æˆ‘å–œæ­¡æŒ‰å°ˆæ¡ˆçµ„ç¹”ã€‚\n",
        "folder_structure = \"Organize by project (MyDrive/Loras/project_name/dataset)\" #@param [\"Organize by category (MyDrive/lora_training/datasets/project_name)\", \"Organize by project (MyDrive/Loras/project_name/dataset)\"]\n",
        "#@markdown æ±ºå®šå°‡ä¸‹è¼‰ä¸¦ç”¨æ–¼è¨“ç·´çš„æ¨¡å‹ã€‚é€™äº›é¸é …æ‡‰è©²æœƒç”¢ç”Ÿä¹¾æ·¨ä¸”ä¸€è‡´çš„çµæœã€‚æ‚¨ä¹Ÿå¯ä»¥é€éè²¼ä¸Šå…¶ä¸‹è¼‰é€£çµä¾†é¸æ“‡æ‚¨è‡ªå·±çš„æ¨¡å‹ã€‚\n",
        "training_model = \"Anime (animefull-final-pruned-fp16.safetensors)\" #@param [\"Anime (animefull-final-pruned-fp16.safetensors)\", \"AnyLora (AnyLoRA_noVae_fp16-pruned.ckpt)\", \"Stable Diffusion (sd-v1-5-pruned-noema-fp16.safetensors)\"]\n",
        "optional_custom_training_model_url = \"\" #@param {type:\"string\"}\n",
        "custom_model_is_based_on_sd2 = False #@param {type:\"boolean\"}\n",
        "\n",
        "if optional_custom_training_model_url:\n",
        "  model_url = optional_custom_training_model_url\n",
        "elif \"AnyLora\" in training_model:\n",
        "  model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt\"\n",
        "elif \"Anime\" in training_model:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
        "else:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
        "\n",
        "#@markdown ### â–¶ï¸ è™•ç†\n",
        "#@markdown Stable Diffusion 1.5 çš„æ¨™æº–è§£æåº¦ç‚º 512ã€‚æ›´é«˜è§£æåº¦çš„è¨“ç·´æœƒæ…¢å¾—å¤šï¼Œä½†å¯ä»¥ç”¢ç”Ÿæ›´å¥½çš„ç´°ç¯€ã€‚<p>\n",
        "#@markdown åœ–ç‰‡åœ¨è¨“ç·´æ™‚æœƒè‡ªå‹•ç¸®æ”¾ä»¥ç”¢ç”Ÿæœ€ä½³çµæœï¼Œå› æ­¤æ‚¨ç„¡éœ€è‡ªå·±è£å‰ªæˆ–èª¿æ•´å¤§å°ã€‚\n",
        "resolution = 512 #@param {type:\"slider\", min:512, max:1024, step:128}\n",
        "#@markdown æ­¤é¸é …å°‡ä»¥æ­£å¸¸å’Œç¿»è½‰çš„æ–¹å¼è¨“ç·´æ‚¨çš„åœ–ç‰‡ï¼Œç„¡éœ€é¡å¤–è²»ç”¨ï¼Œä»¥ä¾¿å¾ä¸­å­¸ç¿’æ›´å¤šã€‚å¦‚æœæ‚¨çš„åœ–ç‰‡å°‘æ–¼ 20 å¼µï¼Œè«‹ç‰¹åˆ¥é–‹å•Ÿæ­¤é¸é …ã€‚<p>\n",
        "#@markdown **å¦‚æœæ‚¨é—œå¿ƒ Lora ä¸­çš„ä¸å°ç¨±å…ƒç´ ï¼Œè«‹é—œé–‰æ­¤é¸é …**ã€‚\n",
        "flip_aug = True #@param {type:\"boolean\"}\n",
        "#markdown ç•™ç©ºè¡¨ç¤ºä¸ä½¿ç”¨æ¨™é¡Œæª”ã€‚\n",
        "caption_extension = \".txt\" #param {type:\"string\"}\n",
        "#@markdown åŸåœ°æ‰“äº‚å‹•æ¼«æ¨™ç±¤å¯ä»¥æ”¹å–„å­¸ç¿’å’Œæç¤ºæ•ˆæœã€‚æ¿€æ´»æ¨™ç±¤ä½æ–¼æ¯å€‹æ–‡å­—æª”æ¡ˆçš„é–‹é ­ï¼Œä¸æœƒè¢«æ‰“äº‚ã€‚\n",
        "shuffle_tags = True #@param {type:\"boolean\"}\n",
        "shuffle_caption = shuffle_tags\n",
        "activation_tags = \"1\" #@param [0,1,2,3]\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "#@markdown ### â–¶ï¸ æ­¥é©Ÿ <p>\n",
        "#@markdown æ‚¨çš„åœ–ç‰‡åœ¨è¨“ç·´æœŸé–“å°‡é‡è¤‡æ­¤æ•¸å­—ã€‚æˆ‘å»ºè­°æ‚¨çš„åœ–ç‰‡æ•¸é‡ä¹˜ä»¥å…¶é‡è¤‡æ¬¡æ•¸ä»‹æ–¼ 200 åˆ° 400 ä¹‹é–“ã€‚\n",
        "num_repeats = 20 #@param {type:\"number\"}\n",
        "#@markdown é¸æ“‡æ‚¨è¦è¨“ç·´å¤šä¹…ã€‚ä¸€å€‹å¥½çš„èµ·é»æ˜¯ç´„ 10 å€‹ Epoch æˆ–ç´„ 2000 å€‹æ­¥é©Ÿã€‚<p>\n",
        "#@markdown ä¸€å€‹ Epoch çš„æ­¥é©Ÿæ•¸ç­‰æ–¼ï¼šæ‚¨çš„åœ–ç‰‡æ•¸é‡ä¹˜ä»¥å…¶é‡è¤‡æ¬¡æ•¸ï¼Œé™¤ä»¥æ‰¹æ¬¡å¤§å°ã€‚<p>\n",
        "preferred_unit = \"Epochs\" #@param [\"Epochs\", \"Steps\"]\n",
        "how_many = 10 #@param {type:\"number\"}\n",
        "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
        "#@markdown å„²å­˜æ›´å¤š Epoch å¯ä»¥è®“æ‚¨æ›´å¥½åœ°æ¯”è¼ƒæ‚¨çš„ Lora é€²åº¦ã€‚\n",
        "save_every_n_epochs = 10 #@param {type:\"number\"}\n",
        "keep_only_last_n_epochs = 1 #@param {type:\"number\"}\n",
        "if not save_every_n_epochs:\n",
        "  save_every_n_epochs = max_train_epochs\n",
        "if not keep_only_last_n_epochs:\n",
        "  keep_only_last_n_epochs = max_train_epochs\n",
        "#@markdown å¢åŠ æ‰¹æ¬¡å¤§å°å¯ä»¥åŠ å¿«è¨“ç·´é€Ÿåº¦ï¼Œä½†å¯èƒ½æœƒä½¿å­¸ç¿’æ•ˆæœè®Šå·®ã€‚å»ºè­°ä½¿ç”¨ 2 æˆ– 3ã€‚\n",
        "train_batch_size = 1 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "#@markdown ### â–¶ï¸ å­¸ç¿’\n",
        "#@markdown å­¸ç¿’ç‡å°æ‚¨çš„çµæœæœ€é‡è¦ã€‚å¦‚æœæ‚¨æƒ³ç”¨å¤§é‡åœ–ç‰‡é€²è¡Œè¼ƒæ…¢çš„è¨“ç·´ï¼Œæˆ–è€…å¦‚æœæ‚¨çš„ dim å’Œ alpha å¾ˆé«˜ï¼Œè«‹å°‡ unet å­¸ç¿’ç‡ç§»è‡³ 2e-4 æˆ–æ›´ä½ã€‚<p>\n",
        "#@markdown æ–‡å­—ç·¨ç¢¼å™¨æœ‰åŠ©æ–¼æ‚¨çš„ Lora ç¨å¾®æ›´å¥½åœ°å­¸ç¿’æ¦‚å¿µã€‚å»ºè­°å°‡å…¶è¨­å®šç‚º unet å­¸ç¿’ç‡çš„ä¸€åŠæˆ–äº”åˆ†ä¹‹ä¸€ã€‚å¦‚æœæ‚¨æ­£åœ¨è¨“ç·´é¢¨æ ¼ï¼Œç”šè‡³å¯ä»¥å°‡å…¶è¨­å®šç‚º 0ã€‚\n",
        "unet_lr = 2e-4 #@param {type:\"number\"}\n",
        "text_encoder_lr = 1e-4 #@param {type:\"number\"}\n",
        "#@markdown èª¿åº¦å™¨æ˜¯æŒ‡å°å­¸ç¿’ç‡çš„æ¼”ç®—æ³•ã€‚å¦‚æœæ‚¨ä¸ç¢ºå®šï¼Œè«‹é¸æ“‡ `constant` ä¸¦å¿½ç•¥æ•¸å­—ã€‚æˆ‘å€‹äººå»ºè­°ä½¿ç”¨ `cosine_with_restarts` ä¸¦é‡æ–°å•Ÿå‹• 3 æ¬¡ã€‚\n",
        "lr_scheduler = \"cosine_with_restarts\" #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
        "lr_scheduler_number = 3 #@param {type:\"number\"}\n",
        "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
        "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
        "#@markdown åœ¨è¨“ç·´æœŸé–“ç”¨æ–¼æé«˜æ•ˆç‡çš„å­¸ç¿’ç‡ã€Œç†±èº«ã€æ­¥é©Ÿã€‚æˆ‘å»ºè­°å°‡å…¶ä¿æŒåœ¨ 5%ã€‚\n",
        "lr_warmup_ratio = 0.05 #@param {type:\"slider\", min:0.0, max:0.5, step:0.01}\n",
        "lr_warmup_steps = 0\n",
        "#@markdown æ–°åŠŸèƒ½ï¼Œéš¨æ™‚é–“èª¿æ•´æå¤±ï¼Œä½¿å­¸ç¿’æ›´æœ‰æ•ˆç‡ï¼Œè¨“ç·´æ™‚é–“å¯ç¸®çŸ­ç´„ä¸€åŠã€‚ä½¿ç”¨è«–æ–‡å»ºè­°çš„ 5.0 å€¼ã€‚\n",
        "min_snr_gamma = True #@param {type:\"boolean\"}\n",
        "min_snr_gamma_value = 5.0 if min_snr_gamma else None\n",
        "\n",
        "#@markdown ### â–¶ï¸ çµæ§‹\n",
        "#@markdown LoRA æ˜¯ç¶“å…¸é¡å‹ï¼Œé©ç”¨æ–¼å„ç¨®ç›®çš„ã€‚LoCon é©ç”¨æ–¼è—è¡“é¢¨æ ¼ï¼Œå› ç‚ºå®ƒæœ‰æ›´å¤šå±¤ä¾†å­¸ç¿’è³‡æ–™é›†çš„æ›´å¤šæ–¹é¢ã€‚\n",
        "lora_type = \"LoRA\" #@param [\"LoRA\", \"LoCon\"]\n",
        "\n",
        "#@markdown ä»¥ä¸‹æ˜¯ä»¥ä¸‹è¨­å®šçš„ä¸€äº›å»ºè­°å€¼ï¼š\n",
        "\n",
        "#@markdown | type | network_dim | network_alpha | conv_dim | conv_alpha |\n",
        "#@markdown | :---: | :---: | :---: | :---: | :---: |\n",
        "#@markdown | LoRA | 16 | 8 |   |   |\n",
        "#@markdown | LoCon | 16 | 8 | 8 | 4 |\n",
        "\n",
        "#@markdown è¼ƒé«˜çš„ dim æ„å‘³è‘—è¼ƒå¤§çš„ Loraï¼Œå®ƒå¯ä»¥åŒ…å«æ›´å¤šä¿¡æ¯ï¼Œä½†æ›´å¤šä¸¦ä¸ç¸½æ˜¯æ›´å¥½ã€‚å»ºè­° dim åœ¨ 8-32 ä¹‹é–“ï¼Œalpha ç­‰æ–¼ dim çš„ä¸€åŠã€‚\n",
        "network_dim = 32 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "network_alpha = 17 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "#@markdown ä»¥ä¸‹å…©å€‹å€¼åƒ…é©ç”¨æ–¼ LoCon çš„é™„åŠ å±¤ã€‚\n",
        "conv_dim = 8 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "conv_alpha = 4 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "\n",
        "network_module = \"networks.lora\"\n",
        "network_args = None\n",
        "if lora_type.lower() == \"locon\":\n",
        "  network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "\n",
        "#@markdown ### â–¶ï¸ æº–å‚™ <p>\n",
        "#@markdown æ‚¨ç¾åœ¨å¯ä»¥åŸ·è¡Œæ­¤å„²å­˜æ ¼ä¾†ã€Œçƒ¹é£ªã€æ‚¨çš„ Lora äº†ã€‚ç¥æ‚¨å¥½é‹ï¼<p>\n",
        "\n",
        "\n",
        "# ğŸ‘©â€ğŸ’» Cool code goes here\n",
        "\n",
        "if optimizer.lower() == \"prodigy\" or \"dadapt\" in optimizer.lower():\n",
        "  if override_values_for_dadapt_and_prodigy:\n",
        "    unet_lr = 0.5\n",
        "    text_encoder_lr = 0.5\n",
        "    lr_scheduler = \"constant_with_warmup\"\n",
        "    lr_warmup_ratio = 0.05\n",
        "    network_alpha = network_dim\n",
        "\n",
        "  if not optimizer_args:\n",
        "    optimizer_args = [\"decouple=True\",\"weight_decay=0.01\",\"betas=[0.9,0.999]\"]\n",
        "    if optimizer == \"Prodigy\":\n",
        "      optimizer_args.extend([\"d_coef=2\",\"use_bias_correction=True\"])\n",
        "      if lr_warmup_ratio > 0:\n",
        "        optimizer_args.append(\"safeguard_warmup=True\")\n",
        "      else:\n",
        "        optimizer_args.append(\"safeguard_warmup=False\")\n",
        "\n",
        "root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "\n",
        "if \"/Loras\" in folder_structure:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "  log_folder    = os.path.join(main_dir, \"_logs\")\n",
        "  config_folder = os.path.join(main_dir, project_name)\n",
        "  images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
        "  output_folder = os.path.join(main_dir, project_name, \"output\")\n",
        "else:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "  images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "  output_folder = os.path.join(main_dir, \"output\", project_name)\n",
        "  config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "  log_folder    = os.path.join(main_dir, \"log\")\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "def install_dependencies():\n",
        "  os.chdir(root_dir)\n",
        "  !git clone {SOURCE} {repo_dir}\n",
        "  os.chdir(repo_dir)\n",
        "  if COMMIT:\n",
        "    !git reset --hard {COMMIT}\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/train_network_wrapper.py -q -O train_network_wrapper.py\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/dracula.py -q -O dracula.py\n",
        "\n",
        "  !apt -y update -qq\n",
        "  !apt -y install aria2 -qq\n",
        "  !pip install -U torch==2.4 xformers triton torchvision==0.19 --index-url https://download.pytorch.org/whl/cu121\n",
        "  !pip install accelerate==0.25.0 transformers==4.36.2 diffusers[torch]==0.25.0 ftfy==6.1.1 \\\n",
        "    opencv-python==4.8.1.78 einops==0.7.0 pytorch-lightning==1.9.0 bitsandbytes==0.43.0 \\\n",
        "    prodigyopt==1.0 lion-pytorch==0.0.6 tensorboard safetensors==0.4.2 altair==4.2.2 \\\n",
        "    easygui==0.98.3 toml==0.10.2 voluptuous==0.13.1 huggingface-hub==0.20.1 imagesize==1.4.1 rich==13.7.1 numpy==1.26.4\n",
        "  !pip install -e .\n",
        "\n",
        "  # patch kohya for minor stuff\n",
        "  if COLAB:\n",
        "    !sed -i \"s@cpu@cuda@\" library/model_util.py # low ram\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # fix truncated jpegs error\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # make epoch names shorter\n",
        "    !sed -i 's/\".\" + args.save_model_as)/\"-{:02d}.\".format(num_train_epochs) + args.save_model_as)/g' train_network.py # name of the last epoch will match the rest\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "def validate_dataset():\n",
        "  global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, keep_tokens_weight, weighted_captions, adjust_tags\n",
        "  supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "  print(\"\\nğŸ’¿ Checking dataset...\")\n",
        "  if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "    print(\"ğŸ’¥ Error: Please choose a valid project name.\")\n",
        "    return\n",
        "\n",
        "  if custom_dataset:\n",
        "    try:\n",
        "      datconf = toml.loads(custom_dataset)\n",
        "      datasets = [d for d in datconf[\"datasets\"][0][\"subsets\"]]\n",
        "    except Exception as e:\n",
        "      print(f\"ğŸ’¥ Error: Your custom dataset is invalid or contains an error! Please check the original template. Details: {e}\")\n",
        "      return\n",
        "    reg = [d.get(\"image_dir\") for d in datasets if d.get(\"is_reg\", False)]\n",
        "    datasets_dict = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datasets}\n",
        "    folders = list(datasets_dict.keys()) # Use folders from custom_dataset\n",
        "\n",
        "    # Validate folders and files within custom_dataset paths\n",
        "    all_files_in_custom_dataset = []\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"ğŸ’¥ Error: The folder {folder.replace('/content/drive/', '')} doesn't exist as specified in custom_dataset.\")\n",
        "            return\n",
        "        files_in_folder = os.listdir(folder)\n",
        "        if not files_in_folder:\n",
        "            print(f\"ğŸ’¥ Error: Your folder {folder.replace('/content/drive/', '')} is empty as specified in custom_dataset.\")\n",
        "            return\n",
        "        for f in files_in_folder:\n",
        "            # Check if item is a file and has a supported extension (excluding directories)\n",
        "            if os.path.isfile(os.path.join(folder, f)) and not f.lower().endswith((\".txt\", \".npz\", *supported_types)):\n",
        "                 print(f\"ğŸ’¥ Error: Invalid file in dataset folder {folder.replace('/content/drive/', '')}: \\\"{f}\\\". Aborting.\")\n",
        "                 return\n",
        "        all_files_in_custom_dataset.extend([os.path.join(folder, f) for f in files_in_folder])\n",
        "\n",
        "\n",
        "    files = all_files_in_custom_dataset # Use files from custom_dataset folders\n",
        "    images_repeats = {folder: (len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.lower().endswith(supported_types)]), datasets_dict[folder]) for folder in folders}\n",
        "\n",
        "  else: # Original logic for single image folder\n",
        "    reg = []\n",
        "    folders = [images_folder]\n",
        "\n",
        "    if not os.path.exists(images_folder):\n",
        "      print(f\"ğŸ’¥ Error: The folder {images_folder.replace('/content/drive/', '')} doesn't exist.\")\n",
        "      return\n",
        "\n",
        "    files = os.listdir(images_folder)\n",
        "\n",
        "    for f in files:\n",
        "        if os.path.isfile(os.path.join(images_folder, f)) and not f.lower().endswith((\".txt\", \".npz\", *supported_types)):\n",
        "             print(f\"ğŸ’¥ Error: Invalid file in dataset: \\\"{f}\\\". Aborting.\")\n",
        "             return\n",
        "\n",
        "    images_in_main_folder = len([f for f in files if os.path.isfile(os.path.join(images_folder, f)) and f.lower().endswith(supported_types)])\n",
        "    images_repeats = {images_folder: (images_in_main_folder, num_repeats)}\n",
        "\n",
        "    if not images_in_main_folder:\n",
        "        print(f\"ğŸ’¥ Error: Your {images_folder.replace('/content/drive/', '')} folder is empty of supported image types.\")\n",
        "        return\n",
        "\n",
        "\n",
        "  if not [f for f in files if os.path.isfile(f) and f.lower().endswith(\".txt\")]:\n",
        "    caption_extension = \"\"\n",
        "  if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "    print(f\"ğŸ’¥ Error: Invalid path to existing Lora. Example: /content/drive/MyDrive/Loras/example.safetensors\")\n",
        "    return\n",
        "\n",
        "  pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
        "  steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
        "  total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
        "  estimated_epochs = int(total_steps/steps_per_epoch)\n",
        "  lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
        "\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    print(\"ğŸ“\"+folder.replace(\"/content/drive/\", \"\") + (\" (Regularization)\" if folder in reg else \"\"))\n",
        "    print(f\"ğŸ“ˆ Found {img} images with {rep} repeats, equaling {img*rep} steps.\")\n",
        "  print(f\"ğŸ“‰ Divide {pre_steps_per_epoch} steps by {train_batch_size} batch size to get {steps_per_epoch} steps per epoch.\")\n",
        "  if max_train_epochs:\n",
        "    print(f\"ğŸ”® There will be {max_train_epochs} epochs, for around {total_steps} total training steps.\")\n",
        "  else:\n",
        "    print(f\"ğŸ”® There will be {total_steps} steps, divided into {estimated_epochs} epochs and then some.\")\n",
        "\n",
        "\n",
        "  if total_steps > 10000:\n",
        "    print(\"ğŸ’¥ Error: Your total steps are too high. You probably made a mistake. Aborting...\")\n",
        "    return\n",
        "\n",
        "  if adjust_tags:\n",
        "    print(f\"\\nğŸ“ Weighted tags: {'ON' if weighted_captions else 'OFF'}\")\n",
        "    if weighted_captions:\n",
        "      print(f\"ğŸ“ Will use {keep_tokens_weight} weight on {keep_tokens} activation tag(s)\")\n",
        "    print(\"ğŸ“ Adjusting tags...\")\n",
        "    adjust_weighted_tags(folders, keep_tokens, keep_tokens_weight, weighted_captions)\n",
        "\n",
        "  return True\n",
        "\n",
        "def adjust_weighted_tags(folders, keep_tokens: int, keep_tokens_weight: float, weighted_captions: bool):\n",
        "  weighted_tag = re.compile(r\"\\((.+?):[.\\d]+\\)(,|$)\")\n",
        "  for folder in folders:\n",
        "    for txt in [f for f in os.listdir(folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(folder, txt), 'r') as f:\n",
        "        content = f.read()\n",
        "      # reset previous changes\n",
        "      content = content.replace('\\\\', '')\n",
        "      content = weighted_tag.sub(r'\\1\\2', content)\n",
        "      if weighted_captions:\n",
        "        # re-apply changes\n",
        "        content = content.replace(r'(', r'\\(').replace(r')', r'\\)').replace(r':', r'\\:')\n",
        "        if keep_tokens_weight > 1:\n",
        "          tags = [s.strip() for s in content.split(\",\")]\n",
        "          for i in range(min(keep_tokens, len(tags))):\n",
        "            tags[i] = f'({tags[i]}:{keep_tokens_weight})'\n",
        "          content = \", \".join(tags)\n",
        "      with open(os.path.join(folder, txt), 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def create_config():\n",
        "  global dataset_config_file, config_file, model_file\n",
        "\n",
        "  if override_config_file:\n",
        "    config_file = override_config_file\n",
        "    print(f\"\\nâ­• ä½¿ç”¨è‡ªè¨‚è¨­å®šæª” {config_file}\")\n",
        "  else:\n",
        "    config_dict = {\n",
        "      \"additional_network_arguments\": {\n",
        "        \"unet_lr\": unet_lr,\n",
        "        \"text_encoder_lr\": text_encoder_lr,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if text_encoder_lr == 0 else None,\n",
        "        \"network_weights\": continue_from_lora if continue_from_lora else None\n",
        "      },\n",
        "      \"optimizer_arguments\": {\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
        "        \"optimizer_type\": optimizer,\n",
        "        \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
        "      },\n",
        "      \"training_arguments\": {\n",
        "        \"max_train_steps\": max_train_steps,\n",
        "        \"max_train_epochs\": max_train_epochs,\n",
        "        \"save_every_n_epochs\": save_every_n_epochs,\n",
        "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"noise_offset\": None,\n",
        "        \"clip_skip\": 2,\n",
        "        \"min_snr_gamma\": min_snr_gamma_value,\n",
        "        \"weighted_captions\": weighted_captions,\n",
        "        \"seed\": 42,\n",
        "        \"max_token_length\": 225,\n",
        "        \"xformers\": XFORMERS,\n",
        "        \"lowram\": COLAB,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"mixed_precision\": \"fp16\",\n",
        "        \"output_dir\": output_folder,\n",
        "        \"logging_dir\": log_folder,\n",
        "        \"output_name\": project_name,\n",
        "        \"log_prefix\": project_name,\n",
        "      },\n",
        "      \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\": model_file,\n",
        "        \"v2\": custom_model_is_based_on_sd2,\n",
        "        \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
        "      },\n",
        "      \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\",\n",
        "      },\n",
        "      \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "      },\n",
        "      \"dataset_arguments\": {\n",
        "        \"cache_latents\": True,\n",
        "      },\n",
        "    }\n",
        "\n",
        "    for key in config_dict:\n",
        "      if isinstance(config_dict[key], dict):\n",
        "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(config_dict))\n",
        "    print(f\"\\nğŸ“„ è¨­å®šæª”å·²å„²å­˜åˆ° {config_file}\")\n",
        "\n",
        "  if override_dataset_config_file:\n",
        "    dataset_config_file = override_dataset_config_file\n",
        "    print(f\"â­• ä½¿ç”¨è‡ªè¨‚è³‡æ–™é›†è¨­å®šæª” {dataset_config_file}\")\n",
        "  else:\n",
        "    dataset_config_dict = {\n",
        "      \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": shuffle_caption,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"flip_aug\": flip_aug,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "        \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
        "        \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
        "      },\n",
        "      \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "        {\n",
        "          \"subsets\": [\n",
        "            {\n",
        "              \"num_repeats\": num_repeats,\n",
        "              \"image_dir\": images_folder,\n",
        "              \"class_tokens\": None if caption_extension else project_name\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    for key in dataset_config_dict:\n",
        "      if isinstance(dataset_config_dict[key], dict):\n",
        "        dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(dataset_config_dict))\n",
        "    print(f\"ğŸ“„ è³‡æ–™é›†è¨­å®šæª”å·²å„²å­˜åˆ° {dataset_config_file}\")\n",
        "\n",
        "def download_model():\n",
        "  global old_model_url, model_url, model_file\n",
        "  real_model_url = model_url.strip()\n",
        "\n",
        "  if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "    model_file = f\"/content{real_model_url[real_model_url.rfind('/'):]}\"\n",
        "  else:\n",
        "    model_file = \"/content/downloaded_model.safetensors\"\n",
        "    if os.path.exists(model_file):\n",
        "      !rm \"{model_file}\"\n",
        "\n",
        "  if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", model_url):\n",
        "    real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "  elif m := re.search(r\"(?:https?://)?(?:www\\\\.)?civitai\\.com/models/([0-9]+)(/[A-Za-z0-9-_]+)?\", model_url):\n",
        "    if m.group(2):\n",
        "      model_file = f\"/content{m.group(2)}.safetensors\"\n",
        "    if m := re.search(r\"modelVersionId=([0-9]+)\", model_url):\n",
        "      real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "    else:\n",
        "      raise ValueError(\"optional_custom_training_model_url contains a civitai link, but the link doesn't include a modelVersionId. You can also right click the download button to copy the direct download link.\")\n",
        "\n",
        "  !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "  if model_file.lower().endswith(\".safetensors\"):\n",
        "    from safetensors.torch import load_file as load_safetensors\n",
        "    try:\n",
        "      test = load_safetensors(model_file)\n",
        "      del test\n",
        "    except:\n",
        "      #if \"HeaderTooLarge\" in str(e):\n",
        "      new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "      !mv \"{model_file}\" \"{new_model_file}\"\n",
        "      model_file = new_model_file\n",
        "      print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "  if model_file.lower().endswith(\".ckpt\"):\n",
        "    from torch import load as load_ckpt\n",
        "    try:\n",
        "      test = load_ckpt(model_file)\n",
        "      del test\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed\n",
        "\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"ğŸ“‚ é€£æ¥åˆ° Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  for dir in (main_dir, deps_dir, repo_dir, log_folder, images_folder, output_folder, config_folder):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  if not validate_dataset():\n",
        "    return\n",
        "\n",
        "  if not dependencies_installed:\n",
        "    print(\"\\nğŸ­ æ­£åœ¨å®‰è£ä¾è³´åº«...\\n\")\n",
        "    t0 = time()\n",
        "    install_dependencies()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\nâœ… å®‰è£å®Œæˆï¼Œè€—æ™‚ {int(t1-t0)} ç§’ã€‚\")\n",
        "  else:\n",
        "    print(\"\\nâœ… ä¾è³´åº«å·²å®‰è£ã€‚\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\nğŸ”„ æ­£åœ¨ä¸‹è¼‰æ¨¡å‹...\")\n",
        "    if not download_model():\n",
        "      print(\"\\nğŸ’¥ éŒ¯èª¤ï¼šæ‚¨é¸æ“‡çš„æ¨¡å‹ç„¡æ•ˆæˆ–å·²æå£ï¼Œæˆ–è€…ç„¡æ³•ä¸‹è¼‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ civitai æˆ– huggingface é€£çµï¼Œæˆ–ä»»ä½•ç›´æ¥ä¸‹è¼‰é€£çµã€‚\")\n",
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\nğŸ”„ æ¨¡å‹å·²ä¸‹è¼‰ã€‚\\n\")\n",
        "\n",
        "  create_config()\n",
        "\n",
        "  print(\"\\nâ­ æ­£åœ¨å•Ÿå‹•è¨“ç·´å™¨...\\n\")\n",
        "  os.chdir(repo_dir)\n",
        "\n",
        "  !accelerate launch --config_file={accelerate_config_file} --num_cpu_threads_per_process=1 train_network_wrapper.py --dataset_config={dataset_config_file} --config_file={config_file}\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHau16lK80iv",
        "outputId": "49b9b876-4569-4973-8d6f-05721d01f8a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBMUJ7BuvNcn"
      },
      "source": [
        "## *ï¸âƒ£ Extras\n",
        "\n",
        "You can run these before starting the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "sy9jU2yrdYar"
      },
      "outputs": [],
      "source": [
        "#@markdown ### ğŸ”® å„ªåŒ–å™¨\n",
        "#@markdown å¦‚æœæ‚¨åŸ·è¡Œæ­¤å„²å­˜æ ¼ï¼Œæ‚¨å°‡æ›´æ”¹ç”¨æ–¼è¨“ç·´çš„å„ªåŒ–å™¨ã€‚å¦å‰‡ï¼Œé è¨­å°‡æ˜¯æ¨è–¦çš„ `AdamW8bit`ã€‚<p>\n",
        "#@markdown * Dadapt å’Œ Prodigy æœƒè‡ªå‹•ç®¡ç†å­¸ç¿’ç‡ï¼Œå°æ–¼å°å‹è³‡æ–™é›†éå¸¸æœ‰æ•ˆã€‚æ‚¨ç„¡éœ€æ›´æ”¹å…¶ä»–ä»»ä½•å…§å®¹å³å¯ä½¿ç”¨å®ƒå€‘ã€‚<p>\n",
        "#@markdown å°æ–¼ Dadapt å’Œ Prodigyï¼Œå¦‚æœå‹¾é¸äº†æ–¹æ¡†ï¼Œä»¥ä¸‹å€¼å°‡è¢«è¦†è“‹ï¼š<p>\n",
        "#@markdown `learning_rate=0.5`, `network_alpha=network_dim`, `lr_scheduler=\"constant_with_warmup\"`, `lr_warmup_ratio=0.05`<p>\n",
        "#@markdown å°æ–¼ Dadapt å’Œ Prodigyï¼Œå¦‚æœ `optimizer_args` ç•™ç©ºï¼Œé è¨­å€¼å°‡ç‚º `decouple=True, weight_decay=0.01, betas=[0.9,0.999]`<p>\n",
        "#@markdown å°æ–¼ Prodigyï¼Œé‚„æœƒé¡å¤–åŒ…å«ï¼š`d_coef=2, use_bias_correction=True, safeguard_warmup=True`<p>\n",
        "optimizer = \"Prodigy\" #@param [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "optimizer_args = \"\" #@param {type:\"string\"}\n",
        "splitter = \", \" if \", \" in optimizer_args else \",\"\n",
        "optimizer_args = [a.strip() for a in optimizer_args.split(splitter) if a]\n",
        "override_values_for_dadapt_and_prodigy = True #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4916Eu1tb9"
      },
      "source": [
        "### ğŸ“š Multiple folders in dataset\n",
        "Below is a template allowing you to define multiple folders in your dataset. You must include the location of each folder and you can set different number of repeats for each one. To add more folders simply copy and paste the sections starting with `[[datasets.subsets]]`.\n",
        "\n",
        "When enabling this, the number of repeats set in the main cell will be ignored, and the main folder set by the project name will also be ignored.\n",
        "\n",
        "You can make one of them a regularization folder by adding `is_reg = true`  \n",
        "You can also set different `keep_tokens`, `flip_aug`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y037lagnJWmn"
      },
      "outputs": [],
      "source": [
        "custom_dataset = \"\"\"\n",
        "[[datasets]]\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/mushroom/dataset/good_images\"\n",
        "num_repeats = 3\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/mushroom/dataset/normal_images\"\n",
        "num_repeats = 1\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W84Jxf-U2TIU"
      },
      "outputs": [],
      "source": [
        "custom_dataset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "-Yq5mNvcCy2l"
      },
      "outputs": [],
      "source": [
        "#@markdown ### ğŸ¤“ å…¶ä»–\n",
        "#@markdown é€™äº›åŠŸèƒ½ä¿ç•™åœ¨æ­¤è™•ï¼Œä¾›å°‘æ•¸ä½¿ç”¨è€…ä½¿ç”¨ã€‚\n",
        "\n",
        "#@markdown æ¬Šé‡æ¨™é¡Œæª”æ˜¯ä¸€é …æ–°åŠŸèƒ½ï¼Œå…è¨±æ‚¨ä½¿ç”¨æ‹¬è™Ÿä¾†å¢åŠ è³‡æ–™é›†ä¸­ç‰¹å®šæ¨™ç±¤çš„æ¬Šé‡ï¼Œèˆ‡æ‚¨çš„ webui æç¤ºè©ç›¸åŒã€‚<p>\n",
        "#@markdown æ¨™ç±¤ä¸­æ­£å¸¸çš„æ‹¬è™Ÿï¼Œä¾‹å¦‚ `(series names)`ï¼Œéœ€è¦åƒ `\\(series names\\)` ä¸€æ¨£é€²è¡Œè½‰ç¾©ã€‚\n",
        "weighted_captions = False #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown é€éå•Ÿç”¨ `adjust_tags`ï¼Œæ‚¨å°‡å…è¨±æ­¤ Colab åœ¨é‹è¡Œä¹‹å‰ä¿®æ”¹æ‚¨çš„æ¨™ç±¤ï¼Œä»¥æ ¹æ“š `weighted_captions` çš„é–‹æˆ–é—œè‡ªå‹•èª¿æ•´ã€‚<p>\n",
        "#markdown ç„¶å¾Œï¼Œæ‚¨å¯ä»¥å¢åŠ  `activation_tag_weight` ä¾†æé«˜æ‚¨çš„æ¿€æ´»æ¨™ç±¤çš„æœ‰æ•ˆæ€§ã€‚\n",
        "adjust_tags = False #param {type:\"boolean\"}\n",
        "activation_tag_weight = \"1.0\" #param [\"1.0\",\"1.1\",\"1.2\"]\n",
        "keep_tokens_weight = float(activation_tag_weight)\n",
        "\n",
        "#@markdown æ‚¨å¯ä»¥åœ¨é€™è£¡å¯«ä¸‹æ‚¨çš„ Google Drive ä¸­çš„è·¯å¾‘ï¼Œä»¥è¼‰å…¥ç¾æœ‰çš„ Lora æª”æ¡ˆç¹¼çºŒè¨“ç·´ã€‚<p>\n",
        "#@markdown **è­¦å‘Šï¼š** é€™èˆ‡ä¸€æ¬¡é•·æ™‚é–“çš„è¨“ç·´æœƒè©±ä¸åŒã€‚Epochs æœƒå¾é ­é–‹å§‹ï¼Œä¸¦ä¸”çµæœå¯èƒ½æœƒæ¯”è¼ƒå·®ã€‚\n",
        "continue_from_lora = \"\" #@param {type:\"string\"}\n",
        "if continue_from_lora and not continue_from_lora.startswith(\"/content/drive/MyDrive\"):\n",
        "  import os\n",
        "  continue_from_lora = os.path.join(\"/content/drive/MyDrive\", continue_from_lora)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "WDjkp4scvPgE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "fe276c8a-e29b-4f44-f598-f45d6ec602bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/my_dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-567048897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/my_dataset.zip'"
          ]
        }
      ],
      "source": [
        "#@markdown ### ğŸ“‚ è§£å£“ç¸®è³‡æ–™é›†\n",
        "#@markdown å°‡å–®å€‹æª”æ¡ˆä¸Šå‚³åˆ°æ‚¨çš„ Drive æœƒæ…¢å¾—å¤šï¼Œå› æ­¤å¦‚æœæ‚¨çš„è³‡æ–™é›†åœ¨æ‚¨çš„é›»è…¦ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¸Šå‚³ä¸€å€‹ zip æª”æ¡ˆã€‚\n",
        "zip = \"/content/drive/MyDrive/my_dataset.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"ğŸ“‚ é€£æ¥åˆ° Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"âœ… å®Œæˆ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "aKWlpsG0jrX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fba4782-569e-4a27-b480-39373ed80352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ é€£æ¥åˆ° Google Drive...\n",
            "\n",
            "Mounted at /content/drive\n",
            "ğŸ“Loras/mushroom/dataset/good_images   |   13 åœ–ç‰‡ |    0 æ¨™é¡Œæª” |\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### ğŸ”¢ è¨ˆç®—è³‡æ–™é›†æª”æ¡ˆæ•¸é‡\n",
        "#@markdown Google Drive ç„¡æ³•è¨ˆç®—è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆæ•¸é‡ï¼Œå› æ­¤é€™å°‡é¡¯ç¤ºæ‰€æœ‰è³‡æ–™å¤¾å’Œå­è³‡æ–™å¤¾ä¸­çš„æª”æ¡ˆæ•¸é‡ã€‚\n",
        "folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"ğŸ“‚ é€£æ¥åˆ° Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} åœ–ç‰‡ | {captions:>4} æ¨™é¡Œæª” |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} å…¶ä»–æª”æ¡ˆ\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"ğŸ“{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDyqB2ytNN08"
      },
      "source": [
        "# ğŸ“ˆ Plot training results\n",
        "You can do this after running the trainer. You don't need this unless you know what you're doing.  \n",
        "The first cell below may fail to load all your logs. Keep trying the second cell until all data has loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdogfLJ_NN08"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir={log_folder}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NC0QOaXNN08"
      },
      "outputs": [],
      "source": [
        "from tensorboard import notebook\n",
        "notebook.display(port=6006, height=800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6972eb0c"
      },
      "source": [
        "# â­ Lora Trainer by Hollowstrawberry\n",
        "\n",
        "é€™æ˜¯åŸºæ–¼ [Kohya-ss](https://github.com/kohya-ss/sd-scripts) å’Œ [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) çš„å·¥ä½œã€‚è¬è¬ï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a8b4db"
      },
      "source": [
        "### â­• å…è²¬è²æ˜\n",
        "æœ¬æ–‡æª”æ—¨åœ¨ç ”ç©¶æ©Ÿå™¨å­¸ç¿’é ˜åŸŸçš„å°–ç«¯æŠ€è¡“ã€‚è«‹é–±è®€ä¸¦éµå®ˆ [Google Colab æŒ‡å—](https://research.google.com/colaboratory/faq.html) åŠå…¶ [æœå‹™æ¢æ¬¾](https://research.google.com/colaboratory/tos_v3.html)ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b495b45"
      },
      "source": [
        "| |GitHub|ğŸ‡¬ğŸ‡§ English|ğŸ‡ªğŸ‡¸ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| ğŸ  **é¦–é ** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| ğŸ“Š **è³‡æ–™é›†è£½ä½œå™¨** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| â­ **Lora è¨“ç·´å™¨** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| ğŸŒŸ **XL Lora è¨“ç·´å™¨** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| ğŸŒŸ **Legacy XL è¨“ç·´å™¨** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99720b9b"
      },
      "source": [
        "## *ï¸âƒ£ é™„åŠ åŠŸèƒ½\n",
        "\n",
        "é€™äº›å¯ä»¥åœ¨é–‹å§‹è¨“ç·´å‰åŸ·è¡Œã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b63acd88"
      },
      "source": [
        "### ğŸ“š è³‡æ–™é›†ä¸­çš„å¤šå€‹è³‡æ–™å¤¾\n",
        "ä»¥ä¸‹æ˜¯ä¸€å€‹æ¨¡æ¿ï¼Œå…è¨±æ‚¨åœ¨è³‡æ–™é›†ä¸­å®šç¾©å¤šå€‹è³‡æ–™å¤¾ã€‚æ‚¨å¿…é ˆåŒ…å«æ¯å€‹è³‡æ–™å¤¾çš„ä½ç½®ï¼Œä¸¦ä¸”å¯ä»¥ç‚ºæ¯å€‹è³‡æ–™å¤¾è¨­å®šä¸åŒçš„é‡è¤‡æ¬¡æ•¸ã€‚è¦æ·»åŠ æ›´å¤šè³‡æ–™å¤¾ï¼Œåªéœ€è¤‡è£½ä¸¦è²¼ä¸Šä»¥ `[[datasets.subsets]]` é–‹é ­çš„éƒ¨åˆ†ã€‚\n",
        "\n",
        "å•Ÿç”¨æ­¤é¸é …æ™‚ï¼Œä¸»å„²å­˜æ ¼ä¸­è¨­å®šçš„é‡è¤‡æ¬¡æ•¸å°‡è¢«å¿½ç•¥ï¼Œä¸¦ä¸”ç”±å°ˆæ¡ˆåç¨±è¨­å®šçš„ä¸»è³‡æ–™å¤¾ä¹Ÿå°‡è¢«å¿½ç•¥ã€‚\n",
        "\n",
        "æ‚¨å¯ä»¥é€šéæ·»åŠ  `is_reg = true` å°‡å…¶ä¸­ä¸€å€‹è¨­ç‚ºæ­£å‰‡åŒ–è³‡æ–™å¤¾ã€‚\n",
        "æ‚¨ä¹Ÿå¯ä»¥è¨­å®šä¸åŒçš„ `keep_tokens`ã€`flip_aug` ç­‰ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afac5517"
      },
      "source": [
        "# ğŸ“ˆ ç¹ªè£½è¨“ç·´çµæœ\n",
        "æ‚¨å¯ä»¥åœ¨é‹è¡Œè¨“ç·´å™¨å¾ŒåŸ·è¡Œæ­¤æ“ä½œã€‚é™¤éæ‚¨çŸ¥é“è‡ªå·±åœ¨åšä»€éº¼ï¼Œå¦å‰‡ä¸éœ€è¦é€™å€‹ã€‚<br>\n",
        "ä¸‹é¢çš„ç¬¬ä¸€å€‹å„²å­˜æ ¼å¯èƒ½ç„¡æ³•è¼‰å…¥æ‰€æœ‰æ—¥èªŒã€‚è«‹ä¸æ–·å˜—è©¦ç¬¬äºŒå€‹å„²å­˜æ ¼ï¼Œç›´åˆ°æ‰€æœ‰æ•¸æ“šéƒ½è¼‰å…¥å®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05bb4bc8"
      },
      "source": [
        "# Task\n",
        "Generate `.txt` caption files for all images in the directory \"/content/drive/MyDrive/Loras/mushroom/dataset\" using the BLIP model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dcd510d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The BLIP model (specifically the `microsoft/git-large-textcaps` model) was successfully used to generate captions for 15 images in the target directory.\n",
        "*   The captioning script initially created files with a `.caption` extension, which were subsequently renamed to the required `.txt` extension.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Ensure that the captioning script is configured to output files directly with the `.txt` extension in future runs to avoid the renaming step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a56b645"
      },
      "source": [
        "## å®‰è£ BLIP ä¾è³´åº«\n",
        "\n",
        "### å­ä»»å‹™ï¼š\n",
        "å®‰è£ä½¿ç”¨ BLIP æ¨¡å‹æ‰€éœ€çš„ Python å‡½å¼åº«ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dd80d39b",
        "outputId": "0a5bec1e-1442-40a1-d081-d5656ac04ce7"
      },
      "source": [
        "# Reasoning: å®‰è£ BLIP æ¨¡å‹æ‰€éœ€çš„ Python å‡½å¼åº«ã€‚\n",
        "import os\n",
        "\n",
        "# Change to the repository directory if necessary\n",
        "# repo_dir = \"/content/kohya-trainer\"\n",
        "# os.chdir(repo_dir)\n",
        "\n",
        "# Install necessary libraries for BLIP\n",
        "!pip install transformers==4.36.2 accelerate==0.25.0\n",
        "!pip install Pillow>=9.0.0\n",
        "!pip install --upgrade google-cloud-storage\n",
        "!pip install open_clip_torch\n",
        "!pip install sentencepiece\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install timm==0.6.13\n",
        "!pip install einops==0.6.1\n",
        "!pip install opencv-python==4.8.1.78"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.36.2\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/126.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m122.9/126.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.25.0\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m567.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, accelerate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.15.2 transformers-4.36.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "nvidia",
                  "tokenizers",
                  "transformers"
                ]
              },
              "id": "01dbaffed05f4dcd9016387020a428f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-3.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.6.15)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n",
            "Downloading google_cloud_storage-3.1.1-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-storage\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.19.0\n",
            "    Uninstalling google-cloud-storage-2.19.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-aiplatform 1.98.0 requires google-cloud-storage<3.0.0,>=1.32.0, but you have google-cloud-storage 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-cloud-storage-3.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "77678c53ef6c4e19b0a51fc985bc4311"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.21.0+cu124)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.33.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.6.15)\n",
            "Downloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 open_clip_torch-2.32.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "google-cloud-aiplatform 1.98.0 requires google-cloud-storage<3.0.0,>=1.32.0, but you have google-cloud-storage 3.1.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "9e4a8c0cab034963beb837c331516c68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.6.13\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from timm==0.6.13) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.6.13) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->timm==0.6.13) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.6.13) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.6.13) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==0.6.13) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7->timm==0.6.13) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.6.13) (2025.6.15)\n",
            "Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "Successfully installed timm-0.6.13\n",
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "Successfully installed einops-0.6.1\n",
            "Collecting opencv-python==4.8.1.78\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.8.1.78) (2.0.2)\n",
            "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "Successfully installed opencv-python-4.8.1.78\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              },
              "id": "b3fbf9c115014f8fa42aabc06db40fd0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279e4bc6"
      },
      "source": [
        "## è¼‰å…¥ BLIP æ¨¡å‹\n",
        "\n",
        "### å­ä»»å‹™ï¼š\n",
        "è¼‰å…¥é è¨“ç·´çš„ BLIP æ¨¡å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd6eb628",
        "outputId": "3dcbae47-70f3-40f3-dc93-fcf230b551bf"
      },
      "source": [
        "# Reasoning: è¼‰å…¥é è¨“ç·´çš„ BLIP æ¨¡å‹ã€‚\n",
        "import os\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "print(\"BLIP æ¨¡å‹è¼‰å…¥å®Œæˆï¼\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLIP æ¨¡å‹è¼‰å…¥å®Œæˆï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aac83403",
        "outputId": "b83968ac-6769-4aa8-ab23-08c8fa345cfe"
      },
      "source": [
        "# ## è¼‰å…¥ BLIP æ¨¡å‹\n",
        "# ### å­ä»»å‹™ï¼š\n",
        "# è¼‰å…¥é è¨“ç·´çš„ BLIP æ¨¡å‹ã€‚\n",
        "# Reasoning: é‡æ–°å˜—è©¦è¼‰å…¥é è¨“ç·´çš„ BLIP æ¨¡å‹ï¼Œå› ç‚ºä¹‹å‰çš„å˜—è©¦å¤±æ•—äº†ã€‚\n",
        "import os\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "print(\"BLIP æ¨¡å‹è¼‰å…¥å®Œæˆï¼\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLIP æ¨¡å‹è¼‰å…¥å®Œæˆï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ca84972"
      },
      "source": [
        "## ä½¿ç”¨ BLIP ç”Ÿæˆä¸¦å„²å­˜æ¨™é¡Œæª” (å¤šè³‡æ–™å¤¾)\n",
        "\n",
        "### å­ä»»å‹™ï¼š\n",
        "éæ­·æŒ‡å®šçš„å¤šå€‹è³‡æ–™é›†è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡æª”æ¡ˆï¼Œä½¿ç”¨è¼‰å…¥çš„ BLIP æ¨¡å‹ç‚ºæ¯å¼µåœ–ç‰‡ç”Ÿæˆæ¨™é¡Œæª”ï¼Œä¸¦å°‡é€™äº›æ¨™é¡Œæª”å„²å­˜åˆ°å°æ‡‰çš„ `.txt` æª”æ¡ˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "748f3db5",
        "outputId": "77901ed2-93a1-4f52-8312-a3a351780b60"
      },
      "source": [
        "# Reasoning: éæ­·æŒ‡å®šçš„å¤šå€‹è³‡æ–™é›†è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡æª”æ¡ˆï¼Œä½¿ç”¨è¼‰å…¥çš„ BLIP æ¨¡å‹ç‚ºæ¯å¼µåœ–ç‰‡ç”Ÿæˆæ¨™é¡Œæª”ï¼Œä¸¦å°‡é€™äº›æ¨™é¡Œæª”å„²å­˜åˆ°å°æ‡‰çš„ .txt æª”æ¡ˆã€‚\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_folders = [\n",
        "     \"/content/drive/MyDrive/Loras/mushroom/dataset\"\n",
        "    # \"/content/drive/MyDrive/Loras/mushroom/dataset/good_images\",\n",
        "    # \"/content/drive/MyDrive/Loras/mushroom/dataset/normal_images\"\n",
        "]\n",
        "\n",
        "supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "for folder_path in image_folders:\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: Folder not found: {folder_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Generating captions for images in: {folder_path}\")\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(supported_extensions)]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No supported image files found in {folder_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        caption_path = os.path.splitext(image_path)[0] + \".txt\"\n",
        "\n",
        "        # Check if caption file already exists\n",
        "        if os.path.exists(caption_path):\n",
        "            print(f\"Caption file already exists for {image_file}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            raw_image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # unconditional image captioning\n",
        "            # inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\") # Use this if CUDA is available and you want to use GPU\n",
        "            inputs = processor(raw_image, return_tensors=\"pt\")\n",
        "\n",
        "            out = model.generate(**inputs)\n",
        "            caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "            with open(caption_path, \"w\") as f:\n",
        "                f.write(caption)\n",
        "\n",
        "            print(f\"Generated caption for {image_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "    print(f\"Finished generating captions for {folder_path}\")\n",
        "\n",
        "print(\"\\nAll caption generation tasks completed.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating captions for images in: /content/drive/MyDrive/Loras/mushroom/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_walk_front.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_back_starbag.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_love_heart.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_birthday_cap_and_cake.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_pingpong.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_crown_cap.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_reading.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_walk_left.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_happy_jump_left.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated caption for dgu_happy_jump_right.png\n",
            "Finished generating captions for /content/drive/MyDrive/Loras/mushroom/dataset\n",
            "\n",
            "All caption generation tasks completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d1eaf12",
        "outputId": "2135d9d4-6533-4d9b-824c-00dd1278dbe7"
      },
      "source": [
        "import os\n",
        "\n",
        "dataset_base_path = \"/content/drive/MyDrive/Loras/mushroom/dataset\"\n",
        "\n",
        "if os.path.exists(dataset_base_path):\n",
        "    print(f\"Contents of {dataset_base_path}:\")\n",
        "    for item in os.listdir(dataset_base_path):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Base dataset path not found: {dataset_base_path}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive/MyDrive/Loras/mushroom/dataset:\n",
            "good_images\n",
            "normal_images\n",
            "dgu_sitting_of_the_left_holding_an_egg.png çš„å‰¯æœ¬\n",
            "dgu_santa_gift.png çš„å‰¯æœ¬\n",
            "dgu_graduation_cap.png çš„å‰¯æœ¬\n",
            "dgu_walk_front.png çš„å‰¯æœ¬\n",
            "dgu_love_heart.png çš„å‰¯æœ¬\n",
            "dgu_pingpong.png çš„å‰¯æœ¬\n",
            "dgu_happy_jump_left.png çš„å‰¯æœ¬\n",
            "dgu_reading.png çš„å‰¯æœ¬\n",
            "dgu_birthday_cap_and_cake.png çš„å‰¯æœ¬\n",
            "dgu_crown_cap.png çš„å‰¯æœ¬\n",
            "dgu_back_starbag.png çš„å‰¯æœ¬\n",
            "dgu_happy_jump_right.png çš„å‰¯æœ¬\n",
            "dgu_walk_left.png çš„å‰¯æœ¬\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b117fed3",
        "outputId": "88757d16-d488-4a26-c027-0c6f33145d0b"
      },
      "source": [
        "# ## ä½¿ç”¨ BLIP ç”Ÿæˆä¸¦å„²å­˜æ¨™é¡Œæª” (å¤šè³‡æ–™å¤¾)\n",
        "# ### å­ä»»å‹™ï¼š\n",
        "# éæ­·æŒ‡å®šçš„å¤šå€‹è³‡æ–™é›†è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡æª”æ¡ˆï¼Œä½¿ç”¨è¼‰å…¥çš„ BLIP æ¨¡å‹ç‚ºæ¯å¼µåœ–ç‰‡ç”Ÿæˆæ¨™é¡Œæª”ï¼Œä¸¦å°‡é€™äº›æ¨™é¡Œæª”å„²å­˜åˆ°å°æ‡‰çš„ `.txt` æª”æ¡ˆã€‚\n",
        "# Reasoning: éæ­·æŒ‡å®šçš„å¤šå€‹è³‡æ–™é›†è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡æª”æ¡ˆï¼Œä½¿ç”¨è¼‰å…¥çš„ BLIP æ¨¡å‹ç‚ºæ¯å¼µåœ–ç‰‡ç”Ÿæˆæ¨™é¡Œæª”ï¼Œä¸¦å°‡é€™äº›æ¨™é¡Œæª”å„²å­˜åˆ°å°æ‡‰çš„ .txt æª”æ¡ˆã€‚\n",
        "import os\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Ensure model and processor are loaded if not already\n",
        "if 'processor' not in globals() or 'model' not in globals():\n",
        "    try:\n",
        "        processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "        model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "        print(\"BLIP æ¨¡å‹å·²è¼‰å…¥ã€‚\")\n",
        "    except Exception as e:\n",
        "        print(f\"ç„¡æ³•è¼‰å…¥ BLIP æ¨¡å‹ï¼š{e}\")\n",
        "        # Exit if model cannot be loaded\n",
        "        exit()\n",
        "\n",
        "\n",
        "image_folders = [\n",
        "     \"/content/drive/MyDrive/Loras/mushroom/dataset\"#,\n",
        "    # \"/content/drive/MyDrive/Loras/mushroom/dataset/good_images\",\n",
        "    # \"/content/drive/MyDrive/Loras/mushroom/dataset/normal_images\"\n",
        "]\n",
        "\n",
        "supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "for folder_path in image_folders:\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: Folder not found: {folder_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Generating captions for images in: {folder_path}\")\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(supported_extensions)]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No supported image files found in {folder_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        caption_path = os.path.splitext(image_path)[0] + \".txt\"\n",
        "\n",
        "        # Check if caption file already exists\n",
        "        if os.path.exists(caption_path):\n",
        "            print(f\"Caption file already exists for {image_file}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            raw_image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "            # unconditional image captioning\n",
        "            # inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\") # Use this if CUDA is available and you want to use GPU\n",
        "            inputs = processor(raw_image, return_tensors=\"pt\")\n",
        "\n",
        "            out = model.generate(**inputs)\n",
        "            caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "            with open(caption_path, \"w\") as f:\n",
        "                f.write(caption)\n",
        "\n",
        "            print(f\"Generated caption for {image_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_file}: {e}\")\n",
        "\n",
        "    print(f\"Finished generating captions for {folder_path}\")\n",
        "\n",
        "print(\"\\nAll caption generation tasks completed.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating captions for images in: /content/drive/MyDrive/Loras/mushroom/dataset\n",
            "No supported image files found in /content/drive/MyDrive/Loras/mushroom/dataset. Skipping.\n",
            "\n",
            "All caption generation tasks completed.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "history_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}